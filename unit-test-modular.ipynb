{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6c645f",
   "metadata": {},
   "source": [
    "# Modular Diffusion Continual Learning Experiment\n",
    "\n",
    "This notebook demonstrates the complete experiment pipeline using modularized functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e69742",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73595f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import the comprehensive experiment runner\n",
    "from src.run_experiment import run_full_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e876304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete experiment for MNIST with normal model size\n",
    "results_mnist = run_full_experiment(\n",
    "    dataset='mnist', \n",
    "    model_size='normal', \n",
    "    n_epochs=200, \n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec450d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment for MNIST with small model (includes full Fisher analysis)\n",
    "results_mnist_small = run_full_experiment(\n",
    "    dataset='mnist', \n",
    "    model_size='small', \n",
    "    n_epochs=100,  # Fewer epochs for small model\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment for CIFAR with normal model size\n",
    "results_cifar = run_full_experiment(\n",
    "    dataset='cifar', \n",
    "    model_size='normal', \n",
    "    n_epochs=200, \n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa134c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results across experiments\n",
    "print(\"EXPERIMENT COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MNIST Normal - Best FID: {min([v for k, v in results_mnist['results'].items() if k.endswith('_fid') and v is not None]):.3f}\")\n",
    "print(f\"MNIST Small - Best FID: {min([v for k, v in results_mnist_small['results'].items() if k.endswith('_fid') and v is not None]):.3f}\")\n",
    "print(f\"CIFAR Normal - Best FID: {min([v for k, v in results_cifar['results'].items() if k.endswith('_fid') and v is not None]):.3f}\")\n",
    "\n",
    "print(f\"\\nOptimal coefficients:\")\n",
    "print(f\"MNIST Normal c*: {results_mnist['c_optimal']:.6f}\")\n",
    "print(f\"MNIST Small c*: {results_mnist_small['c_optimal']:.6f}\")\n",
    "print(f\"CIFAR Normal c*: {results_cifar['c_optimal']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fisher error comparisons\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (name, results) in enumerate([('MNIST Normal', results_mnist), \n",
    "                                   ('MNIST Small', results_mnist_small), \n",
    "                                   ('CIFAR Normal', results_cifar)]):\n",
    "    error_analysis = results['error_analysis']\n",
    "    t_levels = error_analysis['t_levels']\n",
    "    \n",
    "    axes[i].plot(t_levels, np.array(error_analysis['diag_errors'])*10000, label='Diagonal', marker='o')\n",
    "    axes[i].plot(t_levels, np.array(error_analysis['rank1_errors'])*10000, label='Rank-1', marker='s')\n",
    "    axes[i].plot(t_levels, np.array(error_analysis['rank1_optimal_errors'])*10000, label='Optimal Rank-1', marker='^')\n",
    "    axes[i].set_yscale('log')\n",
    "    axes[i].set_xlabel('Timestep Level')\n",
    "    axes[i].set_ylabel('Error Norm (×10⁴)')\n",
    "    axes[i].set_title(f'{name}\\nFisher Approximation Errors')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c2a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Individual component testing (if needed for debugging)\n",
    "from src.experiment_runner import setup_experiment, load_datasets, create_models\n",
    "\n",
    "# Setup experiment with one function call\n",
    "device, ROOT = setup_experiment(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521e248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to archive/data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:19<00:00, 8.70MB/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\cifar-10-python.tar.gz to archive/data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Building DataLoaders for each class in train dataset...\n",
      "Building DataLoaders for each class in train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:24<00:00, 2057.28it/s]\n",
      "100%|██████████| 50000/50000 [00:24<00:00, 2057.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DataLoaders for each class in MNIST test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:05<00:00, 1706.17it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 8.04MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\train-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 3.66MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 7.81MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Building DataLoaders for each class in train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:31<00:00, 1880.56it/s]\n",
      "100%|██████████| 60000/60000 [00:31<00:00, 1880.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DataLoaders for each class in MNIST test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2057.76it/s]\n",
      "100%|██████████| 10000/10000 [00:04<00:00, 2057.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets with one function call\n",
    "datasets = load_datasets(batch_size=128)\n",
    "cl_mnist_train_loaders, cl_mnist_test_loaders = datasets['cl_mnist_train'], datasets['cl_mnist_test']\n",
    "cl_cifar_train_loaders, cl_cifar_test_loaders = datasets['cl_cifar_train'], datasets['cl_cifar_test']\n",
    "print(\"Available test loader keys:\", cl_mnist_test_loaders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models and optimizers with one function call\n",
    "mnist_model, cifar_model, mnist_opt, cifar_opt = create_models(device, model_size='normal')\n",
    "print(f\"MNIST model parameters: {sum(p.numel() for p in mnist_model.parameters() if p.requires_grad)}\")\n",
    "print(f\"CIFAR model parameters: {sum(p.numel() for p in cifar_model.parameters() if p.requires_grad)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
