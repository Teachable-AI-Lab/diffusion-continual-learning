{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e69742",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73595f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import high-level experiment functions\n",
    "from src.experiment_runner import (\n",
    "    setup_experiment, load_datasets, create_models, \n",
    "    train_task_0, compute_fisher_information, \n",
    "    train_continual_learning_tasks, analyze_fisher_errors_across_timesteps,\n",
    "    evaluate_fid, sample_and_visualize\n",
    ")\n",
    "from src.parameter_scoring import compute_param_scores\n",
    "from src.ewc import EWC\n",
    "from src.fisher_analysis import empirical_fisher_dense, optimal_rank1_coeff\n",
    "from src.experimental_utils import analyze_fisher_approximations\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1c2a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup experiment with one function call\n",
    "device, ROOT = setup_experiment(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7521e248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to archive/data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:19<00:00, 8.70MB/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\cifar-10-python.tar.gz to archive/data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Building DataLoaders for each class in train dataset...\n",
      "Building DataLoaders for each class in train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:24<00:00, 2057.28it/s]\n",
      "100%|██████████| 50000/50000 [00:24<00:00, 2057.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DataLoaders for each class in MNIST test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:05<00:00, 1706.17it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 8.04MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\train-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 3.66MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 7.81MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting archive/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to archive/data\\MNIST\\raw\n",
      "\n",
      "Building DataLoaders for each class in train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:31<00:00, 1880.56it/s]\n",
      "100%|██████████| 60000/60000 [00:31<00:00, 1880.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DataLoaders for each class in MNIST test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2057.76it/s]\n",
      "100%|██████████| 10000/10000 [00:04<00:00, 2057.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets with one function call\n",
    "datasets = load_datasets(batch_size=128)\n",
    "cl_mnist_train_loaders, cl_mnist_test_loaders = datasets['cl_mnist_train'], datasets['cl_mnist_test']\n",
    "cl_cifar_train_loaders, cl_cifar_test_loaders = datasets['cl_cifar_train'], datasets['cl_cifar_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20d10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST model parameters: 35743745\n",
      "CIFAR model parameters: 35747331\n",
      "CIFAR model parameters: 35747331\n"
     ]
    }
   ],
   "source": [
    "# Create models and optimizers with one function call\n",
    "mnist_model, cifar_model, mnist_opt, cifar_opt = create_models(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Task 0 with one function call\n",
    "train_task_0(mnist_model, cl_mnist_train_loaders[0], mnist_opt, 200, ROOT, device, \"mnist_model_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "cifar_model.load_state_dict(torch.load( ROOT / \"cifar_model.pth\", map_location=device))\n",
    "mnist_model.load_state_dict(torch.load( ROOT / \"mnist_model_large.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b379de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the modular compute_param_scores function\n",
    "param_scores = compute_param_scores(\n",
    "    mnist_model, \n",
    "    t_level=0, \n",
    "    loaders_by_class=cl_mnist_train_loaders, \n",
    "    device=device, \n",
    "    target_class=0, \n",
    "    max_samples=None\n",
    ")\n",
    "print(f\"Parameter scores shape: {param_scores.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Fisher information with one function call  \n",
    "c, mu, diag, param_scores = compute_fisher_information(mnist_model, cl_mnist_train_loaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76654678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the modular EWC class\n",
    "ewc_diag = EWC(mnist_model, \"diag\", diag=diag)\n",
    "ewc_rank1_opt = EWC(mnist_model, \"rank1_opt\", mu=mu, c=c)\n",
    "ewc_rank1 = EWC(mnist_model, \"rank1\", mu=mu, c=c)\n",
    "\n",
    "print(\"EWC objects created successfully\")\n",
    "print(f\"EWC diagonal loss example: {ewc_diag.loss().item()}\")\n",
    "print(f\"EWC rank1_opt loss example: {ewc_rank1_opt.loss().item()}\")\n",
    "print(f\"EWC rank1 loss example: {ewc_rank1.loss().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Task 1 with different EWC variants using one-liner function calls\n",
    "base_state = torch.load(ROOT / \"mnist_model_large.pth\", map_location=device)\n",
    "\n",
    "# Uncomment any variant you want to train:\n",
    "# mnist_model.load_state_dict(base_state); train_continual_learning_tasks(mnist_model, cl_mnist_train_loaders, optim.Adam(mnist_model.parameters(), lr=2e-4), \"diag\", c, mu, diag, 200, ROOT, device, \"diag\")\n",
    "# mnist_model.load_state_dict(base_state); train_continual_learning_tasks(mnist_model, cl_mnist_train_loaders, optim.Adam(mnist_model.parameters(), lr=2e-4), \"rank1_opt\", c, mu, diag, 200, ROOT, device, \"rank1_opt\")\n",
    "mnist_model.load_state_dict(base_state); train_continual_learning_tasks(mnist_model, cl_mnist_train_loaders, optim.Adam(mnist_model.parameters(), lr=2e-4), \"rank1\", c, mu, diag, 200, ROOT, device, \"rank1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa243d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"c*:\", c.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc05541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the modular compare_fisher_errors_streaming function\n",
    "out = compare_fisher_errors_streaming(\n",
    "    mnist_model, 500, cl_mnist_train_loaders, mu, c, device=device, target_class=0, max_samples=None\n",
    ")\n",
    "print(\"Fisher error comparison results:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ceb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the modular empirical_fisher_dense function\n",
    "Fisher = empirical_fisher_dense(param_scores).to('cpu')  # (D, D)\n",
    "print(f\"Fisher matrix shape: {Fisher.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bed4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the modular optimal_rank1_coeff function\n",
    "c_batch, mu_batch = optimal_rank1_coeff(param_scores, eps=1e-12, use_float64=False)\n",
    "print(\"Optimal coefficient c*:\", c_batch.item())\n",
    "print(f\"Mu shape: {mu_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the modular analyze_fisher_approximations function\n",
    "analysis_results = analyze_fisher_approximations(param_scores, Fisher)\n",
    "print(\"Fisher matrix analysis:\")\n",
    "print(f\"Diagonal error: {analysis_results['diagonal_error']}\")\n",
    "print(f\"Rank-1 error: {analysis_results['rank1_error']}\")\n",
    "print(f\"Optimal rank-1 error: {analysis_results['rank1_optimal_error']}\")\n",
    "print(f\"Optimal coefficient: {analysis_results['optimal_coefficient']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Fisher approximation errors across timesteps with one function call\n",
    "error_analysis = analyze_fisher_errors_across_timesteps(mnist_model, cl_mnist_train_loaders, device, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac3183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print error analysis results\n",
    "print(\"Diagonal Errors:\", error_analysis['diag_errors'])\n",
    "print(\"Rank-1 Errors:\", error_analysis['rank1_errors'])\n",
    "print(\"Optimal Rank-1 Errors:\", error_analysis['rank1_optimal_errors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error analysis with log scale\n",
    "t_levels = error_analysis['t_levels']\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(t_levels, np.array(error_analysis['diag_errors'])*10000, label='Diagonal Error', marker='o')\n",
    "plt.plot(t_levels, np.array(error_analysis['rank1_errors'])*10000, label='Rank-1 Error', marker='o')\n",
    "plt.plot(t_levels, np.array(error_analysis['rank1_optimal_errors'])*10000, label='Optimal Rank-1 Error', marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Timestep Level')\n",
    "plt.ylabel('Error Norm')\n",
    "plt.title('EWC Fisher Matrix Approximation Errors')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the modular functions to analyze Fisher matrix\n",
    "Fisher = Fisher.to('cpu')\n",
    "param_scores = param_scores.to('cpu')\n",
    "\n",
    "# Use the modular optimal_rank1_coeff function \n",
    "c_analysis, mu_analysis = optimal_rank1_coeff(param_scores, eps=1e-12, use_float64=False)\n",
    "\n",
    "# Diagonal approximation\n",
    "F_diag = torch.diag(torch.diag(Fisher))\n",
    "err_diag = torch.linalg.norm(Fisher - F_diag)\n",
    "\n",
    "# Rank-1 approximation with optimal coefficient\n",
    "F_r1_score = mu_analysis.unsqueeze(1) @ mu_analysis.unsqueeze(0) * c_analysis\n",
    "err_r1_score = torch.linalg.norm(Fisher - F_r1_score)\n",
    "\n",
    "print(f\"‖F-F_diag‖_F = {err_diag:.10f},  ‖F-F_r1_score‖_F = {err_r1_score:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for future use\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286cd1e4",
   "metadata": {},
   "source": [
    "# test FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b07a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate FID with one function call\n",
    "fid_cifar = evaluate_fid(cifar_model, cl_cifar_test_loaders[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model variant and evaluate FID with one function call\n",
    "mnist_model.load_state_dict(torch.load(ROOT / \"mnist_model_large-task1-rank1.pth\", map_location=device))\n",
    "fid_mnist = evaluate_fid(mnist_model, cl_mnist_test_loaders[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize samples with one function call\n",
    "samples = sample_and_visualize(mnist_model, device, n_samples=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e69ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available test loaders\n",
    "print(\"Available test loader keys:\", cl_mnist_test_loaders.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
